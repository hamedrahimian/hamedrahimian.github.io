# jemdoc: menu{MENU}{publications.html}
= Publications


~~~
{}{raw}
<p><i>*Indicates student co-author</i></p>
~~~


== Submitted Papers

~~~
{}{raw}
<ul>
<li><p><b>Experimentation Levels and Social Welfare under FDA's Flexible Approval Standards</b>, with S. Delshad* and A. Khademi  </p>
<ul>
<li><p><a href="https://dx.doi.org/10.2139/ssrn.4453707">SSRN May 2023</a></p>
</li>
<li>
<article><p><b>Abstract</b>: 
The FDA sets a uniform hypothesis test's approval standard at the end of Phase III clinical trials for new drugs. We study the impact of flexible approval standards on experimentation and social welfare when pharmaceutical companies (firms) are strategic, especially in terms of the level of experimentation for the new drug. We consider a Stackelberg game with the FDA and two firms in two distinct markets (diseases). The FDA sets the approval standards to maximize social welfare consisting of benefit/cost of approving an effective/ineffective drug, while each firm seeks to maximize its payoff, considering the experimentation cost and potential benefit of entering the market upon approval, which is modeled by an optimal stopping of a diffusion process. We analyze the properties of this Stackelberg game, which has a unique equilibrium under some natural assumptions, and provide comparative statics. Our results show that the shift from uniform to flexible approval standards will increase the approval standard of one market and decrease it for the other market. Consequently, the shift will be beneficial to one market and detrimental to the other. We characterize the conditions under which such a shift is advantageous or disadvantageous for firms conducting research on rare diseases.
</p>
</article> 
</li>
</ul>   
</li>
</ul>
~~~


~~~
{}{raw}
<ul>
<li><p><b>Contextual Expected-Value-Constrained Stochastic Programs</b>, with B. K. Pagnoncelli </p>
<ul>
<li><p><a href="https://optimization-online.org/?p=23244">Optimization-Online May 2023</a></p>
</li>
<li>
<article><p><b>Abstract</b>: 
Expected-value-constrained programming (ECP) formulations are a broad class of stochastic programming problems including integrated chance constraints, risk models, and stochastic dominance formulations. Given the wide availability of data, it is common in applications to have independent contextual information associated with the target or dependent random variables of the problem. We show how to incorporate such information to efficiently approximate ECPs, and prove that the solution set of the approximate problem approaches the true solution set exponentially fast. We illustrate our approach with a portfolio optimization problem that exemplifies the importance of taking contextual information into account in problems with expected-value constraints.
</p>
</article> 
</li>
</ul>   
</li>
</ul>
~~~

~~~
{}{raw}
<ul>
<li><p><b>Mixed-model Sequencing with Stochastic Failures: A Case Study for Automobile Industry</b>, with I. O. Yilmazlar* and M. E. Kurz  </p>
<ul>
<li><p><a href="https://arxiv.org/abs/2306.12618">arXiv May 2023</a></p>
</li>
<li>
<article><p><b>Abstract</b>: 
In the automotive industry, the sequence of vehicles to be produced is determined ahead of the production day. However, there are some vehicles, failed vehicles, that cannot be produced due to some reasons such as material shortage or paint failure. These vehicles are pulled out of the sequence, and the vehicles in the succeeding positions are moved forward, potentially resulting in challenges for logistics or other scheduling concerns.
This paper proposes a two-stage stochastic program for the mixed-model sequencing (MMS) problem with stochastic product failures, and provides improvements to the second-stage problem. To tackle the exponential number of scenarios, we employ the sample average approximation approach and two solution methodologies. On one hand, we develop an L-shaped decomposition-based algorithm, where the computational experiments show its superiority over solving the deterministic equivalent formulation with an off-the-shelf solver. Moreover, we provide a tabu search algorithm in addition to a greedy heuristic to tackle case study instances inspired by our car manufacturer partner. Numerical experiments show that the proposed solution methodologies generate high quality solutions by utilizing a sample of scenarios. Particularly, a robust sequence that is generated by considering car failures can decrease the expected work overload by more than 20\% for both small- and large-sized instances.
</p>
</article> 
</li>
</ul>   
</li>
</ul>
~~~


~~~
{}{raw}
<ul>
<li><p><b>Sequential Convexification of a Bilinear Set</b>, with S. Mehrotra </p>
<ul>
<li><p><a href="http://www.optimization-online.org/DB_HTML/2020/01/7595.html">Optimization-Online August 2022</a></p>
</li>
<li>
<article><p><b>Abstract</b>: 
We present a sequential convexification procedure to derive, in the limit, a set arbitrary close to the convex hull of $\epsilon$-feasible solutions to a general nonconvex continuous bilinear set. Recognizing that bilinear terms can be represented with a finite number nonlinear nonconvex constraints in the lifted matrix space, our procedure performs a sequential convexification with respect to all nonlinear nonconvex constraints. Moreover, our approach relies on generating lift-and-project cuts using simple 0-1 disjunctions, where cuts are generated at all fractional extreme point solutions of the current relaxation. An implication of our convexification procedure is that the constraints describing the convex hull can be used in a cutting plane algorithm to solve a linear optimization problem over the bilinear set to $\epsilon$-optimality.
</p>
</article> 
</li>
</ul>   
</li>
</ul>
~~~


~~~
{}{raw}
<ul>
<li><p><b>A Finitely Convergent Disjunctive Cutting Plane Algorithm for Bilinear Programming</b>, with S. Mehrotra </p>
<ul>
<li><p><a href="http://www.optimization-online.org/DB_HTML/2020/01/7594.html">Optimization-Online August 2022</a></p>
</li>
<li>
<article><p><b>Abstract</b>: 
In this paper we present and analyze a finitely-convergent disjunctive cutting plane algorithm to obtain an $\epsilon$-optimal solution or detect infeasibility of a general nonconvex continuous bilinear program. While the cutting planes are obtained in a manner similar to Saxena, Bonami, and Lee [Math. Prog. 130: 359--413, 2011] and Fampa and Lee [J. Global Optim. 80: 287--305, 2021], a feature of the algorithm that guarantees finite convergence is exploring near-optimal extreme point solutions to a current relaxation at each iteration. In this sense, the presented algorithm and its analysis extend the work Owen and Mehrotra [Math. Prog. 89: 437--448, 2001] for solving mixed-integer linear programs to the general bilinear programs..
</p>
</article> 
</li>
</ul>   
</li>
</ul>
~~~



== Journal Papers

~~~
{}{raw}
<ul>
<li><p><b>Data-Driven Approximation of Contextual Chance-Constrained Stochastic Programs</b>, with B. K. Pagnoncelli </p>
<ul>
<li><p><a href="https://doi.org/10.1137/22M1528045"><i>SIAM Journal on Optimization</i>, 33 (3): 2248-2274</a></p>
</li>
<li>
<article><p><b>Abstract</b>: 
Uncertainty in classical stochastic programming models is often described solely by independent random parameters, ignoring their dependence on multidimensional features. 
We describe a  novel contextual 
chance-constrained programming formulation that incorporates features, and argue that solutions that do not take them into account may not be implementable. Our formulation cannot be solved exactly in most cases, and we propose a tractable and fully data-driven approximate model that relies on weighted sums of random variables. 
We obtain a stochastic lower bound for the optimal value, and feasibility results that include convergence to the true feasible set as number of data points increases, as well as the minimal number of data points needed to obtain a feasible solution with high probability. 
We extend our results for contextual expected-value-constrained stochastic programs, and illustrate our findings on a portfolio selection problem. 
</p>
</article> 
</li>
</ul>   
</li>
</ul>
~~~

~~~
{}{raw}
<ul>
<li><p><b>A Resilient Inventory Management of Pharmaceutical Supply Chains under Demand Disruption</b>, with S. R. Pathy*</p>
<ul>
<li><p><a href="https://doi.org/10.1016/j.cie.2023.109243"><i>Computers & Industrial Engineering</i> 180, 2023</a></p>
</li>
<li>
<article><p><b>Abstract</b>: 
Inspired by the global supply chain disruptions caused by the COVID-19 pandemic, we study optimal procurement and inventory decisions for a pharmaceutical supply chain over a finite planning horizon. To model disruption, we assume that the demand for medical drugs is uncertain and shows spatiotemporal variability. To address demand uncertainty, we propose a two-stage optimization framework, where in the first stage, the total cost of pre-positioning drugs at distribution centers and its associated risk is minimized, while the second stage minimizes the cost of recourse decisions (e.g., reallocation, inventory management). To allow for different risk preferences, we propose to capture the risk of demand uncertainty through the expectation and worst-case measures, leading to two different models, namely (/risk-neutral/) /stochastic programming/ and (/risk-averse/) /robust optimization/. We consider a finite number of scenarios to represent the demand uncertainty, and to solve the resulting models efficiently, we propose L-shaped decomposition-based algorithms. Through extensive numerical experiments, we illustrate the impact of various parameters, such as travel time, product’s shelf life, and waste due to transportation and storage, on the supply chain resiliency and cost, under optimal risk-neutral and risk-averse policies. These insights can assist decision makers in making informed choices.
</p>
</article> 
</li>
</ul>   
</li>
</ul>
~~~

~~~
{}{raw}
<ul>
<li><p><b>Frameworks and Results in Distributionally Robust Optimization</b>, with S. Mehrotra</p>
<ul>
<li><p><a href="https://doi.org/10.5802/ojmo.15"><i>Open Journal of Mathematical Optimization</i>, 3(4): 1-85, 2022</a></p>
</li>
<li>
<article><p><b>Abstract</b>: 
The concepts of risk aversion, chance-constrained optimization, and robust optimization have developed significantly over the last decade. The statistical learning community has also witnessed a rapid theoretical and applied growth by relying on these concepts. A modeling framework, called <i>distributionally robust optimization</i> (DRO), has recently received significant attention in both the operations research and statistical learning communities. This paper surveys main concepts and contributions to DRO, and relationships with robust optimization, risk aversion, chance-constrained optimization, and function regularization. Various approaches to model the distributional ambiguity and their calibrations are discussed. The paper also describes the main solution techniques used to the solve the resulting optimization problems.
</p>
</article> 
</li>
</ul>   
</li>
</ul>
~~~


~~~
{}{raw}
<ul>
<li><p><b>Effective Scenarios in Multistage Distributionally Robust Optimization with a Focus on Total Variation Distance</b>, with G. Bayraksan and T. Homem-de-Mello <br /> </p>
<ul>
<li><p><a href="https://doi.org/10.1137/21M1446484"><i>SIAM Journal on Optimization</i>, 32 (3): 1698-1727</a></p>
</li>
<li><article><p><b>Abstract</b>: We study multistage distributionally robust optimization (DRO) to hedge against ambiguity in quantifying the underlying uncertainty of a problem. Recognizing that not all the realizations and scenario paths might have an &ldquo;effect&rdquo; on the optimal value, we investigate the question of how to define and identify critical scenarios for nested multistage DRO problems. Our analysis extends the work of Rahimian, Bayraksan, and Homem-de-Mello [Math. Program., 173 (2019), pp. 393--430], which was in the context of a static/two-stage setting, to the multistage setting. To this end, we define the notions of effectiveness of scenario paths and the conditional effectiveness of realizations along a scenario path for a general class of multistage DRO problems. We then propose easy-to-check conditions to identify the effectiveness of scenario paths in the multistage setting when the distributional ambiguity is modeled via the total variation distance. Numerical results show that these notions provide useful insight on the underlying uncertainty of the problem.
</p>
</article> 
</li>
</ul>
</li>
</ul>
~~~


~~~
{}{raw}
<ul>
<li><p><b>A Synthetic Data-plus-Features Driven Approach for Portfolio Optimization</b>, with B. K. Pagnoncelli, D. Ramirez*, and A. Cifuentes<br /> </p>
<ul>
<li><p><a href="https://doi.org/10.1007/s10614-022-10274-2"><i>Computational Economics</i>, May 2022</a></p>
</li>
<li><article><p><b>Abstract</b>: Features, or contextual information, are additional data than can help predicting asset returns in financial problems. We propose a mean-risk portfolio selection problem that uses contextual information to maximize expected returns at each time period, weighing past observations via kernels based on the current state of the world. We consider yearly intervals for investment opportunities, and a set of indices that cover the most relevant investment classes. For those intervals, data scarcity is a problem that is often dealt with by making distribution assumptions. We take a different path and use distribution-free simulation techniques to populate our database. In our experiments we use the Conditional Value-at-Risk as our risk measure, and we work with data from 2007 until 2021 to evaluate our methodology. Our results show that, by incorporating features, the out-of-sample performance of our strategy outperforms the equally-weighted portfolio. We also generate diversified positions, and efficient frontiers that exhibit coherent risk-return patterns.
</p>
</article> 
</li>
</ul>
</li>
</ul>
~~~

~~~
{}{raw}
<ul>
<li><p><b>A Model of Supply-Chain Decisions for Resource Sharing with an Application to Ventilator Allocation to Combat COVID-19</b>, with S. Mehrotra, M. Barah, F. Luo, and K. Schantz</p>
<ul>
<li><p><a href="https://doi.org/10.1002/nav.21905"><i>Naval Research Logistics</i>, 67 (5): 303-320</a></p>
</li>
<li><p><b><font color="orange"> Harold W. Kuhn Award 2022 </font> </b></p>
<li><article><p><b>Abstract</b>: 
We present a stochastic optimization model for allocating and sharing a critical resource in the case of a pandemic. The demand for different entities peaks at different times, and an initial inventory for a central agency is to be allocated. The entities (states) may share the critical resource with a different state under a risk-averse condition. The model is applied to study the allocation of ventilator inventory in the COVID-19 pandemic by FEMA to different US states. Findings suggest that if less than 60% of the ventilator inventory is available for non-COVID-19 patients, FEMA's stockpile of 20,000 ventilators (as of 03/23/2020) would be nearly adequate to meet the projected needs in slightly above average demand scenarios. However, when more than 75% of the available ventilator inventory must be reserved for non-COVID-19 patients, various degrees of shortfall are expected. In a severe case, where the demand is concentrated in the top-most quartile of the forecast confidence interval and states are not willing to share their stockpile of ventilators, the total shortfall over the planning horizon (till 05/31/20) is about 232,000 ventilator days, with a peak shortfall of 17,200 ventilators on 04/19/2020. Results are also reported for a worst-case where the demand is at the upper limit of the 95% confidence interval.
</p>
</article> 
</li>
</ul>   
</li>
</ul>
~~~

~~~
{}{raw}
<ul>
<li><p><b>Controlling Demand Ambiguity and Risk in Newsvendor Models</b>, with G. Bayraksan and T. Homem-de-Mello <br /></p>
<ul>
<li><p><a href="https://doi.org/10.1016/j.ejor.2019.06.036"><i>European Journal of Operational Research</i>, 279 (3): 854-868, 2019</a></p>
</li>
<li><article><p><b>Abstract</b>: We use distributionally robust optimization (DRO) to model a general class of newsvendor problems with unknown demand distribution.  The goal is to find an order quantity that minimizes the worst-case expected cost among an ambiguity set of distributions. The ambiguity set consists of those distributions that are not far&#8201;&mdash;&#8201;in the sense of the total variation distance&#8201;&mdash;&#8201;from a nominal distribution. The maximum distance allowed in the ambiguity set (called <i>level of robustness</i>) places the DRO between the risk-neutral stochastic programming and robust optimization models. An important problem a decision maker faces is how to determine the level of robustness—or, equivalently, how to find an appropriate level of risk-aversion. We answer this question in two ways. Our first approach relates the level of robustness and risk to the regions of demand that are critical (in a precise sense we introduce) to the optimal cost. Our second approach establishes new quantitative relationships between the DRO model and the corresponding risk-neutral and classical robust optimization models. To achieve these goals, we first focus on a single-product setting and derive explicit formulas and properties of the optimal solution as a function of the level of robustness. Then, we demonstrate the practical and managerial relevance of our results by applying our findings to a healthcare problem to reserve operating room time for cardiovascular surgeries. Finally, we extend some of our results to the multi-product setting and illustrate them numerically.
</p>
</article> 
</li>
</ul>
</li>
</ul>
~~~

~~~
{}{raw}
<ul>
<li><p><b>Identifying Effective Scenarios in Distributionally Robust Stochastic Programs with Total Variation Distance</b>, with G. Bayraksan and T. Homem-de-Mello <br /> </p>
<ul>
<li><p><a href="https://doi.org/10.1007/s10107-017-1224-6"><i>Mathematical Programming</i>, 173 (1-2): 393-430, 2019</a></p>
</li>
<li><p><b><font color="orange"> Runner-Up, 2017 INFORMS Computing Society Student Paper Award </font></b></p>
</li>
<li><article><p><b>Abstract</b>: Traditional stochastic programs assume that the probability distribution of uncertainty is known. However, in practice, the probability distribution oftentimes is not known or cannot be accurately approximated. One way to address such distributional ambiguity is to work with distributionally robust convex stochastic programs (DRSPs), which minimize the worst-case expected cost with respect to a set of probability distributions. In this paper we analyze the case where there is a finite number of possible scenarios and study the question of how to identify the critical scenarios resulting from solving a DRSP. We illustrate that not all, but only some scenarios might have &ldquo;effect&rdquo; on the optimal value, and we formally define this notion for our general class of problems. In particular, we examine problems where the distributional ambiguity is modeled by the so-called total variation distance. We propose easy-to-check conditions to identify <i>effective</i> and <i>ineffective</i> scenarios for that class of problems. Computational results show that identifying effective scenarios provides useful insight on the underlying uncertainties of the problem.
</p>
</article> 
</li>
</ul>
</li>
</ul>
~~~


~~~
{}{raw}
<ul>
<li><p><b>Optimal Long-Term Distributed Generation Planning and Reconfiguration of Distribution Systems: An Accelerating Benders&rsquo; Decomposition Approach</b>, with S. Khodayifar, M.A. Raayatpanah, A. Rabiee, and P.M. Pardalos</p>
<ul>
<li><p><a href="https://doi.org/10.1007/s10957-018-1367-5"><i>Journal of Optimization Theory and Applications</i>, 179 (1): 283-310, 2018</a></p>
</li>
<li><article><p><b>Abstract</b>: In this paper, we study the multi-period distributed generation planning problem in a multistage hierarchical distribution network. We first formulate the problem as a non-convex mixed-integer nonlinear programming problem. Since the proposed model is non-convex and generally hard to solve, we convexify the model based on semi-definite programming. Then, we use a customized Benders’ decomposition method with valid cuts to solve the convex relaxation model. Computational results show that the proposed algorithm provides an efficient way to solve the problem for relatively large-scale networks.
</p>
</article> 
</li>
</ul>
</li>
</ul>
~~~

~~~
{}{raw}
<ul>
<li><p><b>Decomposition Algorithms for Risk-Averse Multistage Stochastic Programs with Application to Water Allocation under Uncertainty</b>, with W. Zhang and G. Bayraksan <br /></p>
<ul>
<li><p><a href="https://doi.org/10.1287/ijoc.2015.0684"><i>INFORMS Journal on Computing</i>, 28 (3): 385-404, 2016</a></p>
</li>
<li><article><p><b>Abstract</b>: We study a risk-averse approach to multistage stochastic linear programming, where the conditional value-at-risk is incorporated into the objective function as the risk measure. We consider five decompositions of the resulting risk-averse model to solve it via the nested L-shaped method. We introduce separate approximations of the mean and the risk measure and also investigate the effectiveness of multiple cuts. As an application, we formulate a water allocation problem by risk-averse multistage programming, which has the advantage of controlling high-risk severe water shortage events. We apply the proposed formulation to the southeastern portion of Tucson, AZ to best use the limited water resources available to that region. In numerical experiments we (1) present a comparative computational study of the risk-averse nested L-shaped variants and (2) analyze the risk-averse approach to the water allocation problem.
</p>
</article> 
</li>
</ul>
</li>
</ul>
~~~

~~~
{}{raw}
<ul>
<li><p><b>A Comprehensive Dynamic Cell Formation Design: Benders&rsquo; Decomposition Approach</b>, with M. M. Ghotboddini and M. Rabbani <br /></p>
<ul>
<li><p><a href="https://doi.org/10.1016/j.eswa.2010.08.037"><i>Expert Systems with Applications</i>,	38 (3): 2478-2488, 2011</a></p>
</li>
<li><article><p><b>Abstract</b>: This paper is seeking to design a dynamic cellular manufacturing system (DCMS). Area of multi-objective optimization is attractive not only for offering new opportunities for defining problem, but it helps us to extend and solve the anonymous problem. So a new multi-objective mixed integer model is presented for DCMS. The proposed model considers some real-world critical conditions in lean production which are neglected in similar studies in the literature. This model solves the part and machine grouping simultaneously with labor assignment to minimize the cost of various terms like reassignment cost of human resource, over time cost of equipments and labors, and maximize utilization rate of human resource. The model is linearized and validated with GAMS 22.1&copy;plex. Because the Benders&rsquo; decomposition approach has not been applied to solve multi-objective CMS problems so far, we use this method to solve our model. The results are presented at the end.
</p>
</article> 
</li>
</ul>
</li>
</ul>
~~~



== Conference Papers

~~~
{}{raw}
<ul>
<li><p><b>A Classification Method for Ranking and Selection with Covariates</b>, with G. Keslin*, B. N. Nelson, M. Plumlee, B. K. Pagnoncelli<br /></p>
<ul>
<li><p><a href="https://ieeexplore.ieee.org/abstract/document/10015235"><i>Proceedings of the Winter Simulation Conference (WSC '22)</i>, June 2022</a></p>
</li>
<li><article><p><b>Abstract</b>: Ranking & selection (R&S) procedures are simulation-optimization algorithms for making one-time decisions among a finite set of alternative system designs or feasible solutions with a statistical assurance of a good selection. R&S with covariates (R&S+C) extends the paradigm to allow the optimal selection to depend on contextual information that is obtained just prior to the need for a decision. The dominant approach for solving such problems is to employ offline simulation to create metamodels that predict the performance of each system or feasible solution as a function of the covariate. This paper introduces a fundamentally different approach that solves individual R&S problems offline for various values of the covariate, and then treats the real-time decision as a classification problem: given the covariate information,  which system is a good solution? 
Our approach exploits the availability of efficient R&S procedures, requires milder assumptions than the metamodeling paradigm to provide strong guarantees, and can be more efficient. </p>
</article>
</li>
</ul>
</li>
</ul>
~~~


~~~
{}{raw}
<ul>
<li><p><b>A Risk-Averse and Chance-Constrained Two-Stage Stochastic Programming Model for Pharmaceutical Supply Chain Management under Demand Uncertainty</b>, with S. R. Pathy* <br /></p>
<ul>
<li><p><a href="https://www.proquest.com/openview/b838b61aa36780a235e11616eed64a96/1?pq-origsite=gscholar&cbl=51908"><i>Proceedings of the IISE Annual  Conference & Expo</i>, April 2022</a></p>
</li>
<li><article><p><b>Abstract</b>: We study an inventory management problem for a pharmaceutical supply chain under demand uncertainty. To model the problem, we consider a risk-averse two-stage stochastic program, where the maximum value of the cost is minimized. Moreover, we enforce the demand satisfaction with a joint chance constraint. To solve the resulting model, we develop a decomposition algorithm, capable of handling the chance constraint. Numerical experiments shows the computational efficiency of our proposed  algorithm. 
</p>
</article> 
</li>
</ul>
</li>
</ul>
~~~


~~~
{}{raw}
<ul>
<li><p><b>Capacitated Multiple Allocation Hub Location-Covering Problem</b>, with K. Eshghi <br /></p>
<ul>
<li><p><i>Proceedings of the 7th International Industrial Engineering Conference</i>, Isfahan, Iran, 2010</a></p>
</li>
<li><article><p><b>Abstract</b>: In this paper, we study a capacitated multiple allocation hub location problem, where the amount of flow that hub nodes can collect from non-hub nodes is constrained. The underlying network is assumed to be complete and the distance between nodes are assumed to be unstructured, in contrast to the networks in which distances satisfy the triangle inequality. To route the flow on each non-hub to hub link and to prevent constructing underutilized networks, a flow threshold for each non-hub and hub link is assumed. Moreover, in order to improve the service level, a coverage radius is defined for each hub node. As good formulations of mixed-integer programming models are part of the solution process, we identify some properties of the optimal solutions by utilizing the structure of the problem. In addition, we derive facet-defining flow cover and knapsack cover inequalities to strengthen the formulation. The computational experiences on medium sized instances of Australia Post show that generating facet-defining inequalities can significantly improve the lower bound of the usual linear programming relaxation.
</p>
</article> 
</li>
</ul>
</li>
</ul>
~~~


~~~
{}{raw}
<ul>
<li><p><b>Robust Markov Decision Process for Pricing a Portfolio of Real Options</b>, with A. Boostani and M. Modarres <br /> </p>
<ul>
<li><p><i>Proceedings of the 7th International Industrial Engineering Conference</i>, Isfahan, Iran, 2010</p>
</li>
<li><article><p><b>Abstract</b>: Assessing the values of research and development project using pricing a portfolio of real options is an approach that may safeguard against investment risks and may provide opportunities to benefit from the growth in the underlying assets. In this paper, we study a robust Markov decision process approach for pricing a portfolio of risky assets and real options on them. It is assumed that the investment budget is limited and the returns on the underlying assets are uncertain and correlated. Recognizing that the returns on real-world assets are uncertain, the proposed robust Markov decision process may be used for real-world decision-making problems in business and industry. We demonstrate the applicability of our proposed approach on a small problem and obtain the optimal investment policy. 
</p>
</article> 
</li>
</ul>
</li>
</ul>
~~~


~~~
{}{raw}
<ul>
<li><p><b>A New Vehicle Routing Problem Supported by an Improved Ant Colony Optimization</b>, with A. Boostani, M. Rabbani, and M. M. Ghotboddini</p>
<ul>
<li><p><i>Proceedings of the 1st International Logistics and Supply Chain Conference</i>, Tehran, Iran, 2009</p>
</li>
<li><article><p><b>Abstract</b>: The vehicle routing problem (VRP) is a well-known problem on combinatorial optimization and has been proved to be NP-hard. In this paper, with some assumptions, a novel approach to VRP is established. Some central depots exist for goods distribution among customers (multi depot). Customers can both receive and deliver goods from/to central depots such that these operations are done simultaneously by vehicles (simultaneously pickup and delivery). Vehicles, after serving customers, at the end of their routes, will freely choose their end central depots (flexible assignment of depots). Also, each customer’s demand can be met by more than one vehicle (split service). To demonstrate the advantages of taking the mentioned assumption in VRP, the presented model is solved by the proposed Ant Colony Optimization algorithm (ACO) and the results will be presented.
</p>
</article> 
</li>
</ul>
</li>
</ul>
~~~

~~~
{}{raw}
<ul>
<li><p><b>A Bi-Objective Model for Capacitated Multiple Allocation Hub Location Problem-with Flow Threshold and Non-symmetric Flow Matrix</b>, with A. Boostani and M. R. Akbari Jokar <br /></p>
<ul>
<li><p><i>Proceedings of the 1st International Logistics and Supply Chain Conference</i>, Tehran, Iran, 2009</p>
</li>
<li><article><p><b>Abstract</b>: Hub facilities locating problem arises in situation where some flow must be transported from origins to destinations, but it is impossible or too expensive to establish a direct link between each origin/destination pair. In this situation, a group of nodes is chosen to locate hubs. In location allocation problem, hubs are located and origins and destinations nodes will be allocated to hubs. we can probe hub applications in transportation, logistic and telecommunication. 
A different approach to capacitated multiple allocation hub location problem is addressed in this paper. In addition, flow threshold and fixed cost is considered for spoke links. Capacity constraint that limits hub inflow is behaved as a soft constraint rather than a hard. To achieving this purpose, capacity constraint is eliminated and the problem is formulated with a second objective function besides the traditional transportation cost minimizing function. Two bi-criteria MIP models are formulated: In first model, minimization of total time for processing hubs inflow and in second model, minimization of maximum time for processing hubs inflow is considered as second objective function. To solve the models, Goal Programming method is introduced and used. Two bi-criteria models are tested based on AP data set.
</p>
</article> 
</li>
</ul>
</li>
</ul>
~~~


== Preprints


~~~
{}{raw}
<ul>
<li><p><b>Contextual Chance-Constrained Programming</b>, with B. K. Pagnoncelli </p>
<ul>
<li><p><a href="https://optimization-online.org/2020/11/8117/">Optimization-Online December 2020</a></p>
</li>
<li>
<article><p><b>Abstract</b>: 
Uncertainty in classical stochastic programming models is often described solely by independent random parameters, ignoring their dependence on multidimensional features. We describe a novel contextual chance-constrained programming formulation that incorporates features, and argue that solutions that do not take them into account may not be implementable. Our formulation cannot be solved exactly in most cases, and we propose a tractable and fully data-driven approximate model that relies on weighted sums of random variables. Borrowing results from quenched large deviation theory we show the exponential convergence of our scheme as the number of data points increases. We illustrate our findings with an example from a soccer hiring problem based on the player’s transfer market in the UK using real data.
</p>
</article> 
</li>
</ul>   
</li>
</ul>
~~~


~~~
{}{raw}
<ul>
<li><p><b>Distributionally Robust Optimization: A Review</b>, with S. Mehrotra </p>
<ul>
<li><p><a href="https://arxiv.org/abs/1908.05659">arXiv August 2019</a></p>
</li>
<li>
<article><p><b>Abstract</b>: 
The concepts of risk-aversion, chance-constrained optimization, and robust optimization have developed significantly over the last decade. Statistical learning community has also witnessed a rapid theoretical and applied growth by relying on these concepts. A modeling framework, called <i>distributionally robust optimization</i> (DRO), has recently received significant attention in both the operations research and statistical learning communities. This paper surveys main concepts and contributions to DRO, and its relationships with robust optimization, risk-aversion, chance-constrained optimization, and function regularization.  
</p>
</article> 
</li>
</ul>   
</li>
</ul>
~~~



== Thesis

~~~
{}{raw}
<ul>
<li><p><b>Risk-Averse and Distributionally Robust Optimization: Methodology and Applications</b></p>
<ul>
<li><p><a href="https://etd.ohiolink.edu/!etd.send_file?accession=osu1531822931371766&amp;disposition=inline">Ph.D. Thesis, OSU, 2018</a></p>
<li><p><b><font color="orange">2nd Place, 2018 IISE Pritsker Doctoral Dissertation Award </font> </b> </p>
</li>
</li>
<li><article><p><b>Abstract</b>: Many decision-making problems arising in science, engineering, and business involve
uncertainties. One way to address these problems is to use stochastic optimization.
A crucial task when building stochastic optimization models is quantifying a
probability distribution to represent the uncertainty. Most often, partial information
about the uncertainty is available through a series of historical data. In such circumstances,
classical stochastic optimization models rely on approximating the underlying
probability distribution. However, in many real-world applications, the underlying
probability distribution cannot be accurately determined, even when historical data
are available. This distributional ambiguity might lead to highly suboptimal decisions.
An alternative approach to handle such an issue is to use distributionally robust
stochastic optimization (DRSO for short), which assumes the underlying probability
distribution is unknown but lies in an ambiguity set of distributions. <br />
Many existing studies on DRSO focus on how to construct the ambiguity set and
how to transform the resulting DRSO into equivalent (well-studied) models such as
mixed-integer programming and semidefinite programming. This dissertation, however,
addresses more fundamental questions, in a different manner than the literature.
An overarching question that motivates most of this dissertation is which
scenarios/uncertainties are critical to a stochastic optimization problem? A major
contribution of this dissertation is a precise mathematical definition of what is meant by 
a critical scenario and investigation on how to identify them for DRSO. As has
never been done before for DRSO (to the best of our knowledge), we introduce the
notion of effective and ineffective scenarios for DRSO. <br />
This dissertation considers DRSOs for which the ambiguity set contains all probability
distributions that are not far&#8201;&mdash;&#8201;in the sense of the so-called total variation
distance&#8201;&mdash;&#8201;from a nominal distribution (which may be obtained from data). This dissertation
then identifies effective scenarios for two classes of DRSO problems formed
via the total variation distance: (1) a class of convex stochastic optimization problems
with a discrete sample space and (2) a class of inventory problems with a continuous
sample space. <br />
All these classes of DRSO problems have equivalent risk-averse optimization problems
that lay the foundation to identify effective scenarios. We elaborate how effective
scenarios, along with other notions, can be used to choose an appropriate size for
the ambiguity set of distributions. Then, we devise customized algorithms to solve
DRSO formed via the total variation distance. Moreover, we survey existing algorithms
to solve a closely related risk-averse optimization problem to those induced by
the studied DRSO problems, and we propose new variations. Finally, to highlight the
practical relevance of our findings, we implement all our modeling, theoretical, and
computational results to solve problems arising in environment, energy, healthcare,
and finance.
</p>
</article> 
</li>
</ul>
</li>
</ul>
~~~


- *Discrete Optimization in Multiple Allocation Hub Location Problems* 
    -- M.Sc. Thesis, Sharif University of Technology, 2011

- *Modeling and Sensitivity Analysis of the Serving Capability of the Selected Warehouses of Iran Khodro Co. to Production Lines*
    -- B.Sc. Thesis, Sharif University of Technology, 2008

~~~
{}{raw}
<script>
  $('article').readmore({
  speed: 300,
  collapsedHeight: 40,
  heightMargin: 16,
  moreLink: '<a href="#">Read More</a>',
  lessLink: '<a href="#">Read Less</a>',
  embedCSS: true,
  blockCSS: 'display: block; width: 100%;',
  startOpen: false,
  // callbacks
  blockProcessed: function() {},
  beforeToggle: function(){},
  afterToggle: function(){}
  });
  </script>
~~~

